{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hxNbW3ylswh"
      },
      "source": [
        "Sentiment analysis is part of natural language processing (NLP) where the goal is to identify the subjectivity of text data. \n",
        "We will be analyzing amazon reviews and give a numerical rating (1, bad and 5, good). This is a multilabel classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaRNzZQVmA5K"
      },
      "source": [
        "#required librairies \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "\n",
        "### nltk python library for natural language processing \n",
        "\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "####### scikit-learn is a python library for machine learning \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXgIpFMwtf62",
        "outputId": "eee2092f-157a-4a4e-9a43-2ecc3dd7717c"
      },
      "source": [
        "#load the data \n",
        "\n",
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-01 08:47:50--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495854086 (473M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Electronics_5.json.gz’\n",
            "\n",
            "reviews_Electronics 100%[===================>] 472.88M  2.54MB/s    in 4m 12s  \n",
            "\n",
            "2021-10-01 08:52:01 (1.88 MB/s) - ‘reviews_Electronics_5.json.gz’ saved [495854086/495854086]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omf9SbyttgmL"
      },
      "source": [
        "#unzip the file and store in pandas dataframe\n",
        "data_amazon = []\n",
        "with gzip.open('reviews_Electronics_5.json.gz') as f:\n",
        "    for l in f:\n",
        "        data_amazon.append(json.loads(l.strip()))\n",
        "df = pd.DataFrame.from_dict(data_amazon)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "PjhexH_gvR76",
        "outputId": "75e7dad4-0e86-44f8-b515-38f755bdb937"
      },
      "source": [
        "#sample \n",
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AO94DHGC771SJ</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>amazdnu</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Gotta have GPS!</td>\n",
              "      <td>1370131200</td>\n",
              "      <td>06 2, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMO214LNFCEI4</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>[12, 15]</td>\n",
              "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Very Disappointed</td>\n",
              "      <td>1290643200</td>\n",
              "      <td>11 25, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3N7T0DY83Y4IG</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>C. A. Freeman</td>\n",
              "      <td>[43, 45]</td>\n",
              "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1st impression</td>\n",
              "      <td>1283990400</td>\n",
              "      <td>09 9, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1H8PY3QHMQQA0</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Dave M. Shaw \"mack dave\"</td>\n",
              "      <td>[9, 10]</td>\n",
              "      <td>Not going to write a long review, even thought...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Great grafics, POOR GPS</td>\n",
              "      <td>1290556800</td>\n",
              "      <td>11 24, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A24EV6RXELQZ63</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Wayne Smith</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I've had mine for a year and here's what we go...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Major issues, only excuses for support</td>\n",
              "      <td>1317254400</td>\n",
              "      <td>09 29, 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A2JXAZZI9PHK9Z</td>\n",
              "      <td>0594451647</td>\n",
              "      <td>Billy G. Noland \"Bill Noland\"</td>\n",
              "      <td>[3, 3]</td>\n",
              "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>HDMI Nook adapter cable</td>\n",
              "      <td>1388707200</td>\n",
              "      <td>01 3, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A2P5U7BDKKT7FW</td>\n",
              "      <td>0594451647</td>\n",
              "      <td>Christian</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>The cable is very wobbly and sometimes disconn...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cheap proprietary scam</td>\n",
              "      <td>1398556800</td>\n",
              "      <td>04 27, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AAZ084UMH8VZ2</td>\n",
              "      <td>0594451647</td>\n",
              "      <td>D. L. Brown \"A Knower Of Good Things\"</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>This adaptor is real easy to setup and use rig...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A Perfdect Nook HD+ hook up</td>\n",
              "      <td>1399161600</td>\n",
              "      <td>05 4, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AEZ3CR6BKIROJ</td>\n",
              "      <td>0594451647</td>\n",
              "      <td>Mark Dietter</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>This adapter easily connects my Nook HD 7&amp;#34;...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>A nice easy to use accessory.</td>\n",
              "      <td>1405036800</td>\n",
              "      <td>07 11, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A3BY5KCNQZXV5U</td>\n",
              "      <td>0594451647</td>\n",
              "      <td>Matenai</td>\n",
              "      <td>[3, 3]</td>\n",
              "      <td>This product really works great but I found th...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>This works great but read the details...</td>\n",
              "      <td>1390176000</td>\n",
              "      <td>01 20, 2014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
              "0   AO94DHGC771SJ  0528881469  ...     1370131200   06 2, 2013\n",
              "1   AMO214LNFCEI4  0528881469  ...     1290643200  11 25, 2010\n",
              "2  A3N7T0DY83Y4IG  0528881469  ...     1283990400   09 9, 2010\n",
              "3  A1H8PY3QHMQQA0  0528881469  ...     1290556800  11 24, 2010\n",
              "4  A24EV6RXELQZ63  0528881469  ...     1317254400  09 29, 2011\n",
              "5  A2JXAZZI9PHK9Z  0594451647  ...     1388707200   01 3, 2014\n",
              "6  A2P5U7BDKKT7FW  0594451647  ...     1398556800  04 27, 2014\n",
              "7   AAZ084UMH8VZ2  0594451647  ...     1399161600   05 4, 2014\n",
              "8   AEZ3CR6BKIROJ  0594451647  ...     1405036800  07 11, 2014\n",
              "9  A3BY5KCNQZXV5U  0594451647  ...     1390176000  01 20, 2014\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "QrJ_OPfH1Lxo",
        "outputId": "b7ccd46b-1bfe-4588-a172-79f93670d793"
      },
      "source": [
        "#take only rating and text \n",
        "\n",
        "df_overall_text = df[['reviewText','overall']]\n",
        "\n",
        "df_overall_text.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Not going to write a long review, even thought...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I've had mine for a year and here's what we go...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          reviewText  overall\n",
              "0  We got this GPS for my husband who is an (OTR)...      5.0\n",
              "1  I'm a professional OTR truck driver, and I bou...      1.0\n",
              "2  Well, what can I say.  I've had this unit in m...      3.0\n",
              "3  Not going to write a long review, even thought...      2.0\n",
              "4  I've had mine for a year and here's what we go...      1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "mNr166NGEcli",
        "outputId": "e51c5297-e63b-454d-e68b-514873cab45c"
      },
      "source": [
        "#overall description \n",
        "\n",
        "df_overall_text.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.689188e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.222779e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.185632e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            overall\n",
              "count  1.689188e+06\n",
              "mean   4.222779e+00\n",
              "std    1.185632e+00\n",
              "min    1.000000e+00\n",
              "25%    4.000000e+00\n",
              "50%    5.000000e+00\n",
              "75%    5.000000e+00\n",
              "max    5.000000e+00"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jd3_n3qvPC1",
        "outputId": "2479b6aa-2e1b-4ebc-e66f-2e7f2f14d418"
      },
      "source": [
        "#missing and nan values\n",
        "\n",
        "df_overall_text.isna().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "reviewText    0\n",
              "overall       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGdX_MUkvrWK",
        "outputId": "ddcd3be8-c98b-46ea-ca66-1845a23c00f0"
      },
      "source": [
        "df_overall_text.count()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "reviewText    1689188\n",
              "overall       1689188\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFjO-kuVvy5X",
        "outputId": "306724f3-6ddf-45a1-e2d9-140b411c4132"
      },
      "source": [
        "#drop rows with missing values\n",
        "df_overall_text.dropna(inplace=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n15F_J5Kv5cE",
        "outputId": "081f01ef-2efc-44eb-f4ce-7fbd98a0c658"
      },
      "source": [
        "#count unique ratings unbalanced ??\n",
        "df_overall_text.overall.value_counts()\n",
        "\n",
        "sample_size = df_overall_text.overall.value_counts()\n",
        "print(sample_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0    1009026\n",
            "4.0     347041\n",
            "3.0     142257\n",
            "1.0     108725\n",
            "2.0      82139\n",
            "Name: overall, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMeVohahwTxa"
      },
      "source": [
        "#downsamling to be as the least represented rating\n",
        "\n",
        "df_equal_proportion = pd.DataFrame()\n",
        "for i in df_overall_text.overall.unique():\n",
        "  X = df_overall_text[df_overall_text.overall == i].sample(82000)\n",
        "  df_equal_proportion = df_equal_proportion.append(X)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT6TQ_6HzeY1",
        "outputId": "9834549a-2ad8-4c4d-d7ef-91ade187b671"
      },
      "source": [
        "df_equal_proportion['overall'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0    82000\n",
              "5.0    82000\n",
              "4.0    82000\n",
              "2.0    82000\n",
              "1.0    82000\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZT-Sq_Y1Vp6",
        "outputId": "b2a5eea7-4491-49f2-fea5-5bb085c4fe65"
      },
      "source": [
        "#lets load ntlk libraries that we will use to preprocess the text\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet, stopwords"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPDvkWFg1fYk"
      },
      "source": [
        "stopwords_list = stopwords.words('english')\n",
        "\n",
        "def ReviewProcessing(df):\n",
        "  # remove non alphanumeric \n",
        "  df['review_non_alphanumeric'] = df.reviewText.str.replace('[^a-zA-Z0-9 ]', '')\n",
        "  # lowercase\n",
        "  df.review_non_alphanumeric = df.review_non_alphanumeric.str.lower()\n",
        "  # split into list\n",
        "  df.review_non_alphanumeric = df.review_non_alphanumeric.str.split(' ')\n",
        "  # remove stopwords\n",
        "  df.review_non_alphanumeric = df.review_non_alphanumeric.apply(lambda x: [item for item in x if item not in stopwords_list])\n",
        "  return df"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPFpkA82R-m"
      },
      "source": [
        "#identify and cut down the inflectional forms into a common base word.\n",
        "def get_wordnet_pos(word):\n",
        "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "  tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "  return tag_dict.get(tag, wordnet.NOUN)\n",
        "#lemmatizing\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def get_lemmatize(sent):\n",
        "  return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sent)])\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syjo8pjF3Jb7"
      },
      "source": [
        "clean_data = ReviewProcessing(df_equal_proportion)\n",
        "clean_data.review_non_alphanumeric = clean_data.review_non_alphanumeric.apply(' '.join)\n",
        "clean_data['review_cleaned_lemmatized'] = clean_data.review_non_alphanumeric.apply(get_lemmatize)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7IP74Sj3qH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d6c46ff4-8334-4abe-974a-fd1fd6bf2b58"
      },
      "source": [
        "clean_data.head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>review_non_alphanumeric</th>\n",
              "      <th>review_cleaned_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>240062</th>\n",
              "      <td>This is by far the best FM transmitter I have ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>far best fm transmitter ever usedit easy use s...</td>\n",
              "      <td>far best fm transmitter ever usedit easy use s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555796</th>\n",
              "      <td>I bought a Garmin Nuvi 350 a while back (paid ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>bought garmin nuvi 350 back paid around 800 fi...</td>\n",
              "      <td>bought garmin nuvi 350 back paid around 800 fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63529</th>\n",
              "      <td>Used these more than once in older cars as a r...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>used older cars replacement new set  easy inst...</td>\n",
              "      <td>use old car replacement new set easy install i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67826</th>\n",
              "      <td>Just got theSony VMC15FS A/V Cable for most So...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>got thesony vmc15fs av cable sony minidv  dvd ...</td>\n",
              "      <td>get thesony vmc15fs av cable sony minidv dvd c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495131</th>\n",
              "      <td>This is just cool. It's actually made by SONY ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>cool actually made sony customized camera woul...</td>\n",
              "      <td>cool actually make sony customize camera would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788689</th>\n",
              "      <td>MyNikon D80 10.2MP Digital SLR Camera (Body on...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>mynikon d80 102mp digital slr camera body only...</td>\n",
              "      <td>mynikon d80 102mp digital slr camera body only...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595624</th>\n",
              "      <td></td>\n",
              "      <td>5.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1117608</th>\n",
              "      <td>The Canadian Kindle Keyboard did not come with...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>canadian kindle keyboard come handy adapter  u...</td>\n",
              "      <td>canadian kindle keyboard come handy adapter u ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665952</th>\n",
              "      <td>It's the cheapest charger i ever had and it wo...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>cheapest charger ever works really liked compl...</td>\n",
              "      <td>cheapest charger ever work really like complai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695756</th>\n",
              "      <td>I've bought five of these over the last year. ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>ive bought five last year far better deal walm...</td>\n",
              "      <td>ive bought five last year far well deal walmar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                reviewText  ...                          review_cleaned_lemmatized\n",
              "240062   This is by far the best FM transmitter I have ...  ...  far best fm transmitter ever usedit easy use s...\n",
              "555796   I bought a Garmin Nuvi 350 a while back (paid ...  ...  bought garmin nuvi 350 back paid around 800 fi...\n",
              "63529    Used these more than once in older cars as a r...  ...  use old car replacement new set easy install i...\n",
              "67826    Just got theSony VMC15FS A/V Cable for most So...  ...  get thesony vmc15fs av cable sony minidv dvd c...\n",
              "1495131  This is just cool. It's actually made by SONY ...  ...  cool actually make sony customize camera would...\n",
              "788689   MyNikon D80 10.2MP Digital SLR Camera (Body on...  ...  mynikon d80 102mp digital slr camera body only...\n",
              "595624                                                      ...                                                   \n",
              "1117608  The Canadian Kindle Keyboard did not come with...  ...  canadian kindle keyboard come handy adapter u ...\n",
              "665952   It's the cheapest charger i ever had and it wo...  ...  cheapest charger ever work really like complai...\n",
              "695756   I've bought five of these over the last year. ...  ...  ive bought five last year far well deal walmar...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBs0vgVgXcFL"
      },
      "source": [
        "#save the file to csv \n",
        "clean_data.to_csv('amazon_review_lema.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6yPnpJPYD--"
      },
      "source": [
        "#lets create a pipeline that will vectorize the data as ingrams of two and then uses term frequency-inverse doccument frequency to represent the text numerically\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "nb = Pipeline([('vectorize', CountVectorizer(ngram_range=(1, 2))),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier()),\n",
        "               ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(max_iter=500)),\n",
        "               ])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx7NKJ_IZHvx"
      },
      "source": [
        "x = clean_data['review_cleaned_lemmatized']\n",
        "y = clean_data['overall']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, \n",
        "                                                    test_size=0.2, stratify=y, random_state = 44)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVSPhnZPZNdh",
        "outputId": "8eb137f3-a1a8-41f6-b137-67408276a8cc"
      },
      "source": [
        "\n",
        "# Naive Bayes\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_nb))\n",
        "print(confusion_matrix(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# SGD Classifier\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_sgd))\n",
        "print(confusion_matrix(y_test, y_pred_sgd))\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "\n",
        "# Logistic Regression\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_log = logreg.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_log))\n",
        "print(confusion_matrix(y_test, y_pred_log))\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.464\n",
            "[[9468 4960 1289  518  165]\n",
            " [3948 7150 3567 1528  207]\n",
            " [1869 4010 5431 4542  548]\n",
            " [ 829 1561 2459 9638 1913]\n",
            " [ 883 1009 1002 7145 6361]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.56      0.58      0.57     16400\n",
            "         2.0       0.38      0.44      0.41     16400\n",
            "         3.0       0.40      0.33      0.36     16400\n",
            "         4.0       0.41      0.59      0.48     16400\n",
            "         5.0       0.69      0.39      0.50     16400\n",
            "\n",
            "    accuracy                           0.46     82000\n",
            "   macro avg       0.49      0.46      0.46     82000\n",
            "weighted avg       0.49      0.46      0.46     82000\n",
            "\n",
            "0.47324390243902437\n",
            "[[13422   993   701   337   947]\n",
            " [ 8227  2917  2388  1163  1705]\n",
            " [ 3630  1945  4231  3375  3219]\n",
            " [ 1255   577  1726  5142  7700]\n",
            " [ 1003   258   539  1506 13094]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.49      0.82      0.61     16400\n",
            "         2.0       0.44      0.18      0.25     16400\n",
            "         3.0       0.44      0.26      0.33     16400\n",
            "         4.0       0.45      0.31      0.37     16400\n",
            "         5.0       0.49      0.80      0.61     16400\n",
            "\n",
            "    accuracy                           0.47     82000\n",
            "   macro avg       0.46      0.47      0.43     82000\n",
            "weighted avg       0.46      0.47      0.43     82000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRnLEQRlZi_-"
      },
      "source": [
        "#can we improve it better with tunning the hyperparameters gridsearch \n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid=[{'clf__solver': ['lbfgs', 'sag', 'saga'],\n",
        "       'clf__C': [0.01, 0.1, 1]}]\n",
        "lr = GridSearchCV(logreg, param_grid = grid, cv = 5, scoring='accuracy', verbose = 1, n_jobs = -1)\n",
        "best_model = lr.fit(X_train, y_train)\n",
        "\n",
        "print(best_model.best_estimator_)\n",
        "print(best_model.best_score_)\n",
        "\n",
        "y_pred_grid = best_model.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred_grid))\n",
        "print(classification_report(y_test, y_pred_grid))\n",
        "print(accuracy_score(y_test, y_pred_grid))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}